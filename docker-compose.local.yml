version: "3.8"
services:
  backend-flask:
    environment:
      FRONTEND_URL: "${FRONTEND_URL}"
      BACKEND_URL: "${BACKEND_URL}"

      #jwt verification
      AWS_DEFAULT_REGION: "${AWS_DEFAULT_REGION}"
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
      AWS_COGNITO_USER_POOL_ID: "${AWS_USER_POOLS_ID}"
      AWS_COGNITO_USER_POOL_CLIENT_ID: "${CLIENT_ID}"


      # CONNECTION_URL: "${PROD_CONNECTION_URL}" 
      CONNECTION_URL: "${LOCAL_CONNECTION_URL}"

      AWS_ENDPOINT_URL: "http://dynamodb-local:8000"
      # # openTelemetry
      # OTEL_SERVICE_NAME: "backend-flask"
      # OTEL_EXPORTER_OTLP_ENDPOINT: "https://api.honeycomb.io"
      # OTEL_EXPORTER_OTLP_HEADERS: "x-honeycomb-team=${HONEYCOMB_API_KEY}"


      # # AWS XRAY
      # AWS_XRAY_URL: "*4567-${GITPOD_WORKSPACE_ID}.${GITPOD_WORKSPACE_CLUSTER_HOST}*"
      # AWS_XRAY_DAEMON_ADDRESS: "xray-daemon:2000"

      # Rollbar
      ROLLBAR_ACCESS_TOKEN: "${ROLLBAR_ACCESS_TOKEN}"


    build: ./backend-flask

    # build:
    #   context: ./backend-flask
    #   args:
    #     AWS_ACCOUNT_ID: ${AWS_ACCOUNT_ID}
    #   dockerfile: Dockerfile.prod

    ports:
      - "4567:4567"
    networks:
      - cruddur-net

    # healthcheck:
    #   test: curl --fail ${BACKEND_URL}/api/health-check || exit 1
    #   interval: 10s
    #   timeout: 10s
    #   start_period: 10s
    #   retries: 3

    volumes:
      - ./backend-flask:/backend-flask

  frontend-react-js:
    environment:
      REACT_APP_BACKEND_URL: "${BACKEND_URL}"
      REACT_APP_FRONTEND_URL: "${FRONTEND_URL}"
      REACT_APP_OTEL_COLLECTOR_URL: "${OTEL_COLLECTOR_URL}"

      # for cognito
      REACT_APP_AWS_PROJECT_REGION: "${AWS_DEFAULT_REGION}"
      REACT_APP_AWS_COGNITO_REGION: "${AWS_DEFAULT_REGION}"
      REACT_APP_AWS_USER_POOLS_ID: "${AWS_USER_POOLS_ID}"
      REACT_APP_CLIENT_ID: "${CLIENT_ID}"
      REACT_APP_API_GATEWAY_ENDPOINT_URL: "${REACT_APP_API_GATEWAY_ENDPOINT_URL}"
      # ------------

    build: ./frontend-react-js

    ports:
      - "3000:3000"
    networks:
      - cruddur-net

    # healthcheck:
    #   test: curl --fail ${FRONTEND_URL} || exit 1
    #   interval: 300s
    #   timeout: 10s
    #   start_period: 10s
    #   retries: 3
    volumes:
      - ./frontend-react-js:/frontend-react-js

  dynamodb-local:
    # https://stackoverflow.com/questions/67533058/persist-local-dynamodb-data-in-volumes-lack-permission-unable-to-open-databa
    # We needed to add user:root to get this working.
    user: root
    command: "-jar DynamoDBLocal.jar -sharedDb -dbPath ./data"
    image: "amazon/dynamodb-local:latest"
    container_name: dynamodb-local
    ports:
      - "8000:8000"
    networks:
      - cruddur-net
    volumes:
      - "./docker/dynamodb:/home/dynamodblocal/data"
    working_dir: /home/dynamodblocal


  db:
    image: postgres:13-alpine
    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    ports:
      - '5432:5432'
    networks:
      - cruddur-net
    volumes: 
      - db:/var/lib/postgresql/data

  xray-daemon:
    image: "amazon/aws-xray-daemon"
    environment:
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
      AWS_REGION: "us-east-1"
    command:
      - "xray -o -b xray-daemon:2000"
    ports:
      - 2000:2000/udp
    networks:
      - cruddur-net

networks: 
  cruddur-net:
    driver: bridge
    name: cruddur-net
  
volumes:
  db:
    driver: local


  # # OTEL Collector
  # otel-collector:
  #   environment:
  #      HONEYCOMB_API_KEY: "${HONEYCOMB_API_KEY}"
  #      FRONTEND_URL_WITHOUT_HTTP: "localhost:3000"
  #   image: otel/opentelemetry-collector
  #   command: [--config=/etc/otel-collector-config.yaml]
  #   volumes:
  #     - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
  #   ports:
  #     - 4318:4318 # OTLP http receiver




  # the name flag is a hack to change the default prepend folder
  # name when outputting the image names

  # for envoy proxy
  # front-envoy:
  #   build:
  #     context: ./envoy-proxy
  #     dockerfile: Dockerfile-frontenvoy
  #   depends_on:
  #     backend-flask:
  #       condition: service_healthy
  #   environment:
  #     FRONT_ENVOY_YAML: "config/http-service.yaml"
  #   ports:
  #     - "${PORT_PROXY:-8000}:8000"

  # ext_authz-http-service:
  #   build:
  #     context: ./envoy-proxy/auth
  #     dockerfile: Dockerfile
  #   environment:
  #     AWS_USER_POOLS_ID: "${AWS_USER_POOLS_ID}"
  #     CLIENT_ID: "${CLIENT_ID}"


